import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.catalyst.plans.JoinType
object joinDF extends App {
  val spark = SparkSession.builder
    .appName("DataFrameJoinExample")
    .master("local[*]")
    .getOrCreate()
  val df1 = spark.createDataFrame(Seq(
    (1, "Alice"),
    (2, "Bob"),
    (3, "Charlie")
  )).toDF("id", "name")

  val df2 = spark.createDataFrame(Seq(
    (1, "2024-01-01"),
    (2, "2024-01-02"),
    (4, "2024-01-04")
  )).toDF("id", "date")
  val innerJoinDF = df1.join(df2, Seq("id"), "inner")
  innerJoinDF.show()

  val fullouterJoinDF = df1.join(df2, Seq("id"),"outer")
  fullouterJoinDF.show()
}
